---
title: 'Lista de Exercícios'
academic: Eduardo Elias Ribeiro Junior
email: 'edujrrib@gmail.com'
chair: LCE5859 - Métodos Estatísticos Multivariados
institute: 'Escola Superior de Agricultura Luiz de Queiroz - USP'
date: '\today'
logo: "configs/logo-esalq.png"
bibliography: lce5859-mem.bib
csl: configs/abntcite.csl
output:
  pdf_document:
    template: configs/template.tex
    keep_tex: false
---

Resolução dos exercícios propostos durante a disciplina LCE5859 -
Métodos Estatísticos Multivariados, ministrada pelo professor
[Carlos Tadeu dos Santos Dias][carlos] pelo Programa de Pós-Graduação em
Estatística e Experimentação Agronômica da ESALQ-USP como curso de
verão. Os exercícios são descritos no livro _Métodos Estatísticos
Multivariados: uma introdução_ [@Manly2008], que também é adotado como
livro-texto na disciplina. Todas as análises presentes nesse documento
são realizadas com o software R [@Rcore2016] e estão disponíveis (texto
e códigos) no endereço <https://github.com/jreduardo/lce5859-mem>. Os
dados utilizados foram carregados do pacote `labestData`
[@labestData2016], que mantém digitado e documentado todos os dados
presentes no livro-texto.

\vspace{3cm}
\tableofcontents
\pagebreak

```{r, include=FALSE}

##----------------------------------------------------------------------
## Reports
library(knitr)
library(xtable)
opts_chunk$set(
    warning = FALSE,
    message = FALSE,
    cache = FALSE,
    echo = FALSE,
    results = "hide",
    fig.width = 7,
    fig.height = 5,
    fig.align = "center",
    fig.pos = "H",
    out.width = "1\\textwidth",
    dev.args = list(
        family = "Palatino")
    )
options(
    digits = 3,
    xtable.comment = FALSE,
    xtable.caption.placement = "top",
    xtable.table.placement = "H"
)

##----------------------------------------------------------------------
## Load packages

library(labestData)         ## Datas
library(reshape2)           ## Manipule data
library(plyr)               ## Manipule data

## For graphics
library(lattice)
library(latticeExtra)
source("configs/setup.R")
cols <- trellis.par.get("superpose.line")$col

```

\pagebreak

# Testes de Significância com Dados Multivariados

```{r}

##======================================================================
## Exercise chapter 4
##======================================================================

##----------------------------------------------------------------------
## Packages
library(car)

##----------------------------------------------------------------------
## Functions

## Modify print Manova function for exibe table tests
outtests <- car:::print.Anova.mlm
body(outtests)[[16]] <- quote(invisible(tests))
body(outtests)[[15]] <- NULL

## Modify print LinearHypothesis function for exibe table tests
outcontrasts <- car:::print.linearHypothesis.mlm
body(outcontrasts)[[21]] <- quote(invisible(tests))
body(outcontrasts)[[22]] <- NULL

##----------------------------------------------------------------------
## Load and organize data
## help(ManlyTb4.5, h = "html")
da <- transform(ManlyTb4.5, sexo = factor(sexo))
levels(da$grup) <- c("Modernos", "Pré-históricos",
                     "Chacais", "Cuons", "Indianos")
da$grup <- relevel(da$grup, ref = "Pré-históricos")
levels(da$sexo) <- c("Desconhecido", "Macho", "Fêmea")

```

Esse exercício refere-se à aplicação dos métodos apresentados no
capítulo 4 do livro-texto. O conjunto de dados disponibilizado diz
respeito à comparação entre cães pré-históricos da Tailândia e outros
quatro grupos de animais (cães modernos da Tailândia, chacais dourados,
cuons e lobos indianos) em termos de nove medidas de mandíbula:

 * $X_1$ Comprimento da mandíbula (mm).
 * $X_2$ Largura da mandíbula, abaixo do primeiro molar (mm).
 * $X_3$ Largura do côndilo aricular (mm).
 * $X_4$ Altura da mandíbula, abaixo do primeiro molar (mm).
 * $X_5$ Comprimento do primeiro molar (mm).
 * $X_6$ Largura do primeiro molar (mm).
 * $X_7$ Comprimento do primeiro ao terceiro molar (mm).
 * $X_8$ Comprimento do primeiro ao quarto pré-molar (mm).
 * $X_9$ Largura do canino inferior (mm).

Por simplicidade iremos considere a abreviação Pré-históricos, Modernos,
Chacais, Cuons e Indianos para os grupos cães pré-históricos da
Tailândia, cães modernos da Tailândia, chacais dourados, cuons e lobos
indianos respectivamente.

Nesse conjunto de dados há também a informação sobre o sexo de todos os
cães, exceto os pré-históricos. Foram avaliados `r nrow(da)` cães, cujo
10 pertenciam ao grupo dos cães Pré-históricos, 16 ao grupo dos cães
Modernos, 20 ao grupo dos cães Chacais, 17 ao grupo dos cães Cuons e 14
ao grupo cães Indianos. Na \autoref{fig:box-dist} são apresentados o
comportamento das 9 medidas de mandíbulas para cada grupo canino (à
esquerda) e a matriz de distâncias multivariadas (à direita). Observe
que a distribuição marginal empírica das variáveis $X_i$,
$i=1,2,\ldots,9$ difere em cada grupo canino tanto em posição (medianas
diferentes) quanto em dispersão (amplitudes diferentes). No gráfico à
direita são exibidas as distâncias entre os vetores médios dos grupos
caninos, calculadas como
\begin{equation}
    \label{eqn:euclidean-dist}
    d(i, j) = \sqrt{\sum_{k=1}^{9}(\bar{x}_{ki}-\bar{x}_{kj})^2}
\end{equation}
sendo $\bar{x}_{ki}$ a média da k-ésima medida para o i-ésimo grupo, i e
j variam de 1 a 5 conforme os cinco grupos caninos. Portanto $d(i, j)$
representa a distância multivariada entre os grupos caninos $i$ e $j$ em
mm. Observa-se que a maior diferença entre os vetores médios se dá entre
os grupos Chacais e Indianos, enquanto que a menor se dá entre
Pré-históricos e Modernos.

```{r box-dist, fig.height=4.5, fig.width = 10, fig.cap="Box-plots das nove medidas de mandíbula para cada grupo canino (esquerda) e matriz de distâncias multivariadas entre os grupos caninos (direita)."}

##----------------------------------------------------------------------
## Descriptive analysis

## Boxplot data
da_long <- melt(da[,-11], id.vars = "grup")
codvars <- parse(text = paste0("X[", seq(ncol(da)-2), "]"))
xy1 <- bwplot(value ~ grup | variable,
              axis = axis.grid,
              data = da_long,
              as.table = TRUE,
              layout = c(3, 3),
              ylab = "",
              scales = list(x = list(rot = 30), y = "free"),
              strip = strip.custom(
                  factor.levels = codvars)
              )

## Means distance matrix visualization
da_means <- sapply(da[, -c(1, 11)], function(x) {
    tapply(x, da$grup, mean)
})
xy2 <- levelplot(as.matrix(dist(da_means)),
                 xlab = "",
                 ylab = "",
                 scales = list(x = list(rot = 30)),
                 panel = function(x, y, z, ...) {
                     ## print(as.list(...))
                     panel.levelplot(x, y, z, ...)
                     panel.text(x, y, round(z, 2))
                 })

## Visualization
print(xy1, split = c(1, 1, 2, 1), more = TRUE)
print(xy2, split = c(2, 1, 2, 1), more = FALSE)

```

Um dos interesses levantados sobre esse estudo é em testar as diferenças
entre os vetores médios dos grupos caninos a fim de identificar,
principalmente se há diferenças entre os cães Pré-histórios e os
demais. Uma representação do perfil médio de cada grupo canino é
apresentada na \autoref{fig:stars} em forma de gráficos de radar onde a
magnitude da média de cada medida é apresentada de forma conjunta para
cada grupo, essa é uma forma alternativa aos gráficos-estrela descritos
em @Manly2008 [capítulo 3]. A leitura dessa figura é análoga a leitura
da representação da matriz de distâncias na \autoref{fig:box-dist}.

```{r stars, fig.height=3, fig.width=9, fig.cap="Gráficos-radar representando as médias de cada medida da mandíbula para cada grupo canino."}

## Star graph
stars(da_means,
      draw.segments = TRUE,
      nrow = 1,
      col.segments = cols,
      ## key.labels = codvars,
      ## key.loc = c(8.7, 3.2),
      flip.labels = FALSE,
      radius = FALSE,
      frame.plot = TRUE## ,
      ## mar = c(1, 1, 2, 1)
      )
par(xpd = TRUE)
## polygon(c(1, 1, 10, 10), c(6, 0.5, 0.5, 6))
legend("top", codvars, fill = cols,
       horiz = TRUE, bty = "n", inset = -0.1)

```

O método para comparação entre vetores médios quando se tem mais de duas
amostras é denominado MANOVA (_Multivariate Analysis of Variance_) e o
teste de significância para $H_0$: $\underline{\mu_i} =
\underline{\mu_j}$ $\forall\, i \neq j$ pode ser realizado via
diferentes estatísticas . Nesse trabalho consideramos as estatísticas
Traço de Pillai-Bartlett, Traço de Hotelling-Lawley, Lambda de Wilks e
Raiz máxima de Roy tanto para MANOVA como para contrastes multivariados,
conforme descrito em @Fox2011.

Na análise de variância multivariada para comparação de médias para
várias amostas, o teste pressupõe a normalidade multivariada dentro dos
grupos e homogeneidade nas matrizes de variâncias e covariâncias. Para
verificar a normalidade multivariada procedeu-se com o teste de Mardia
com correção para pequenas amostras [@Korkmaz]. Os resultados são
apresentados na \autoref{tab:assumptions}. Note que não há sérias
evidências de assimétria para todos os grupos, pois a hipótese testade é
a de não assimétria da distribuição, assim para todos os grupos
obteve-se níveis descritivos superiores a 0.20. Quando consideramos a
curtose da distribuição, os dados para os grupos _Pré-históricos_ e
_Indianos_ apresentaram níveis descritivos do teste que sustentam a
rejeição da hipótese nula, que neste caso é de que a curtose da
distribuição é coerente com a distribuição Normal multivariada.

```{r, results="asis"}

cap <- paste("Teste de Mardia para normalidade mutivariada.",
             "Estatísticas de teste e respecitvos níveis",
             "descritivos entre parênteses.")

## Mutivariate normality by group
ass1 <- do.call(
    rbind, lapply(
               split(da[, -c(1, 11)], da$grup),
               function(x) {
                   res <- MVN::mardiaTest(x)
                   s1 <- formatC(res@chi.small.skew, 3, format = "f")
                   s2 <- formatC(res@p.value.small, 4, format = "f")
                   k1 <- formatC(res@z.kurtosis, 3, format = "f")
                   k2 <- formatC(res@p.value.kurt, 4, format = "f")
                   cbind("Assimétria" = paste(s1, "(", s2, ")"),
                         "Curtose" = paste(k1, "(", k2, ")"))
               }))
rownames(ass1) <- levels(da$grup)

## Equals variances and covariances matrices
ass2 <- biotools::boxM(da[, -c(1, 11)], da$grup)

## Latex table
print(xtable(ass1,
             caption = cap,
             label = "tab:assumptions"))

```

A segunda suposição, de matrizes de variâncias e covariâncias
iguais para todos os grupos, foi avaliada pelo teste de M de Box
[@Manly2008] que resultou na estatística `r ass2$stat` com um _p-valor_
de $`r ass2$p.value`$ o que evidência a rejeição da hipótese nula de
matrizes de variâncias e covariâncias homôgeneas.

Claramente nota-se que algumas suposições não foram atendidas. Aqui
dar-se-á continuidade ao estudo deixando de lado as suposições. Algumas
estatísticas são mais robustas a falta de normalidade e a
heterogeneidade das matrizes de variâncias e covariâncias, como o traço
de Pillai e portanto devem ser preferíveis, porém todos serão
prejudicadas.

```{r, results="asis"}

##----------------------------------------------------------------------
## Multivariate analysis of variance

model <- lm(cbind(compm, largmapm, largca, altmapm, comppm, largpm,
                  compptm, comppqp, largci) ~ grup, data = da)

## Global statistical tests
mtests <- c("Pillai", "Wilks", "Hotelling-Lawley", "Roy")
tab_global <- do.call(rbind, lapply(mtests, function(i) {
    x <- outtests(Anova(model, test.statistic = i))
    class(x) <- "data.frame"
    x
}))
rownames(tab_global) <- mtests

## Resultados em formato de tabela Latex
cap <- c("Tabela de análise de variância multivariada global (MANOVA)")
print(xtable(tab_global, digits = c(0, 0, 4, 4, 0, 2, -3),
             caption = cap,
             label = "tab:manova")
      )

```


Na \autoref{tab:contrasts} são apresentados os resultados da análise de
variância multivariada (MANOVA) com as diferentes estatísticas citadas
anteriormente. Note que todas as estatísticas indicam que há um pelo
menos um par de vetores de médias diferentes dentro os 10 pares
possíveis (5 grupos). Esse resultado já era esperado, pois como
apresentado naas análises descritivas, há grupos bastante distintos.

```{r}

## Linear Hypothesis Tests (contrasts)
HM <- cbind(0, -1 * diag(4))
tab_contr <- do.call(rbind, lapply(seq(nrow(HM)), function(i) {
    x <- outcontrasts(
        linearHypothesis(model, hypothesis.matrix = HM[i, ]))
    class(x) <- "data.frame"
    x
}))
tab_contr$Statistic <- rep(mtests, nrow(HM))
tab_contr$Contrast <- do.call(
    "c", strsplit(paste(
             paste("\\underline{Pré-Históricos = ",
                   levels(da$grup)[-1]), "};;;;"), ";"))

```

Na \autoref{tab:contrasts} são apresentados os resultados dos testes
para contrastes multivariados de médias do grupo _Pré-histórico_ contra
os demais dois a dois. Note que os testes acusaram diferenças em todos
os contrastes, indicando que o vetor das médias das medidas para os cães
_Pré-históricos_ é diferente de todos os demais, porém com um nível
descritivo demasiadamente menor quando contrastado com as médias
calculadas para os cães modernos. Todavia vale ressaltar que esses
resultados foram influenciados pela não verificação dos pressupostos.

```{r, results="asis"}

cap <- c("Tabela de contrastes multivariados")
print(xtable(tab_contr[c(8, 7, 1:6)],
             digits = c(0, 0, 0, 0, 4, 4, 0, 2, -3),
             caption = cap,
             label = "tab:contrasts"),
      include.rownames = FALSE,
      sanitize.text.function = identity)

```

A fim de avaliar o quão próximos foram os dados mensurados para os cães
_Pré-histórios_ e _Modernos_ a \autoref{fig:perfis2} é
apresentada. Nessa figura a distribuição de densidade empírica das nova
variáveis para os dois grupos é exibida à esquerda. Note que há grande
similaridade das distribuições, com algumas exceções como para $X_1$
(comprimento da mandíbula) que tem variabilidade maior para os
_Pré-históricos_. O mesmo ocorre para $X_4$, $X_6$ e $X_7$. À direita da
figura têm-se um gráfico de perfil, onde boxplots das nove medidas são
apresentados para cada grupo, unindo as médias por linhas. Analogamente
ao gráfico anterior nota-se para $X_6$ (largura do primeiro molar) a
maior diferença entre as medidas. Nesse gráfico é nítido que as médidas
calculadas nos dois grupos são bastante pŕoximas o que evidência que os
resultados apontados pelos testes de contrastes não é confiável devido a
não verificação dos pressupostos.

```{r perfis2, fig.height=5, fig.width=10}

##----------------------------------------------------------------------
## Comparação das distribuições das 9 variáveis entre os caes
## tailandeses
subda_long <- droplevels(
    subset(da_long, grup %in% c("Pré-históricos", "Modernos")))

## Distribuições empíricas das variaveis
xy1 <- densityplot(~value | variable,
                   data = subda_long,
                   scales = "free",
                   groups = grup,
                   axis = axis.grid,
                   as.table = TRUE,
                   layout = c(3, 3),
                   auto.key = TRUE,
                   xlab = "",
                   strip = strip.custom(
                       factor.levels = codvars)
                   )

## Gráfico do perfil mediano
##   - Ordenando as variaveis
ordvar <- order(aggregate(value ~ variable, subda_long, mean)[["value"]])
subda_long$variable <- ordered(subda_long$variable,
                               levels =
                                   levels(da_long$variable)[ordvar])

gap <- 0.15; widt <- 0.2
xy2 <- bwplot(value ~ variable,
              data = subda_long,
              axis = axis.grid,
              xlab = "Variáveis",
              ylab = "Valores Observados",
              scales = list(x = list(labels = codvars[ordvar])),
              subset = grup == "Modernos",
              horizontal = FALSE,
              box.width = widt,
              fill = cols[1],
              col = cols[1],
              alpha = 0.5,
              panel = function(x, y, subscripts, ...) {
                  panel.xyplot(x = as.integer(x) - gap, y,
                               type = "a", ...)
                  panel.bwplot(x = as.integer(x) + gap, y = y, ...)
              }) +
    as.layer(
        bwplot(value ~ variable,
               data = subda_long,
               subset = grup == "Pré-históricos",
               horizontal = FALSE,
               box.width = widt,
               fill = cols[2],
               col = cols[2],
               alpha = 0.5,
               panel = function(x, y, subscripts, ...) {
                   panel.xyplot(x = as.integer(x) - gap, y,
                                type = "a", ...)
                   panel.bwplot(x = as.integer(x) - gap, y = y, ...)
               })
    )

## Visualization
print(xy1, split = c(1, 1, 2, 1), more = TRUE)
print(xy2, split = c(2, 1, 2, 1), more = FALSE)

```

\pagebreak

# Medindo e Testando Distâncias Multivariadas

```{r, include=FALSE}

##======================================================================
## Exercise chapter 5
##======================================================================

##----------------------------------------------------------------------
## Packages
library(biotools)

##----------------------------------------------------------------------
## Functions

## Distance matrix for proportion data
pdist <- function(x, diag = FALSE, upper = FALSE) {
    n <- nrow(x)
    aux <- t(combn(n, 2))
    out <- apply(aux, 1, function(ind) {
        sum(abs(x[ind[1], ] - x[ind[2], ]))
    })
    attr(out, "class") <- "dist"
    attr(out, "Size") <- n
    attr(out, "Diag") <- diag
    attr(out, "Upper") <- upper
    attr(out, "method") <- "euclidean"
    return(out)
}

##----------------------------------------------------------------------
## Load and organize data
## help(ManlyTb1.3, h = "html")
da <- ManlyTb1.3

## Define ambiental and genetics variables
ambvars <- c("alt", "precip", "tempmax", "tempmin")
genvars <- c("dg0.4", "dg0.6", "dg0.8", "dg1", "dg1.16", "dg1.3")

da[, ambvars] <- scale(da[, ambvars])
da[, genvars] <- da[, genvars] / 100

```

Esse exercício é descrito ao final do capítulo 5 do livro-texto, onde
propõe-se a análise de um conjunto de dados que traz o registro de 4
variáveis ambientais e de proporções gênicas de _Fósforo
Glucose-Isomerase_ (Pgi) para 6 diferentes tipos genéticos de Pgi. Os
registrados foram feitos em `r nrow(da)` colônias de borboletas
_Euphydryas editha_ na Califórnia e Oregon. Uma breve descrição das
variáveis é realizada abaixo:

* Variáveis ambientais:
    - $X_{A1}$: Altitude (pés);
    - $X_{A2}$: Precipitação anual (polegadas);
    - $X_{A3}$: Temperatura máxima (ºF);
    - $X_{A4}$: Temperatura mínima (ºF).

* Proporções de mobilidade gênica Pgi:
    - $X_{G1}$: Para o tipo génetico de Pgi 0.40;
    - $X_{G2}$: Para o tipo génetico de Pgi 0.60;
    - $X_{G3}$: Para o tipo génetico de Pgi 0.80;
    - $X_{G4}$: Para o tipo génetico de Pgi 1.00;
    - $X_{G5}$: Para o tipo génetico de Pgi 1.16;
    - $X_{G6}$: Para o tipo génetico de Pgi 1.30;

Para as proporções de mobilidade gênica Pgi $\sum X_{Gi} =
1$. Na \autoref{fig:splom-ecdf} são apresentados dois gráficos que
descrevem o corportamente das variáveis ambientais e genéticas. No
gráfico da esquerda as variáveis ambientais são dispostas em gráficos de
dispersão aos pares. Observa-se que as colônias GH e GL são as que mais
diferem das demais colônias, sendo essas colônias de alta altitude e
baixas temperaturas. No gráfico a direita são apresentadas as proporções
acumuladas das freqências gênicas registradas em cada colônia. Destes
perfis gênicos as colônias que mais se destacam são a GH e LO, que
acumulam uma proporção maior de mobilidade gênica nos primeiros tipos de
Pgi (0.4, 0.6 e 1.0).

```{r splom-ecdf, fig.height=5, fig.width=10, fig.cap="Gráfico de dispersão por pares entre as variáveis ambientais (esquerda). Proporções acumuladas de mobilidade gênica dos cinco diferentes tipos genéticos de Pgi."}

##----------------------------------------------------------------------
## Descriptive analysis
da <- cbind(da, expand.grid(pch = c(8, 19),
                            color = cols[1:8],
                            stringsAsFactors = FALSE))
pspace <- list(layout.heights = list(top.padding = 10))

## For ambiental variables
codvarsa <- parse(text = paste0("X[A", 1:length(ambvars), "]"))
xy1 <- splom(~da[, ambvars],
             groups = col,
             data = da,
             varnames = codvarsa,
             xlab = "",
             par.settings = list(
                 layout.heights = list(top.padding = 10)
             ),
             pscales = lapply(da[, ambvars], function(x) {
                 list(limits = extendrange(x, f = 0.2))
             }),
             diag.panel = function(x, ...){
                 yrng <- current.panel.limits()$ylim
                 d <- density(x, na.rm = TRUE)
                 d$y <- with(d, yrng[1] + 0.9 * diff(yrng) * y / max(y))
                 panel.polygon(
                     x = c(d$x, rev(d$x)),
                     y = c(d$y, rep(min(d$y), length(d$y))),
                     col = "gray80", border = "white")
                 diag.panel.splom(x, ...)
             },
             panel = function(x, y, groups, ...) {
                 panel.grid()
                 panel.points(x, y,
                              col = da$color,
                              pch = da$pch,
                              cex = 1.1, alpha = 0.8)
                 ## panel.text(x, y - 0.1, groups,
                 ##            cex = 0.6, col = "gray50")
             })

## For genetics variables (note they are percentage)
aux <- cbind(da[, c("col", "pch", "color")],
             as.data.frame(t(apply(da[, genvars], 1, cumsum))))

da_long <- melt(aux, id.vars = c("col", "pch", "color"))
codvarsg <- parse(text = paste0("X[G", 1:length(genvars), "]"))

xy2 <- xyplot(value ~ variable,
              groups = col,
              data = da_long,
              type = c("g", "l", "p"),
              xlab = "",
              ylab = "Proporções acumuladas de Pgi",
              scales = list(x = list(labels = codvarsg)),
              par.settings = list(
                 layout.heights = list(top.padding = 9)
             ),
              panel = function(x, y, groups, ...) {
                  panel.xyplot(x, y, groups, ...,
                               col = da$color, pch = da$pch)
              })

## Legend for graphics
key <- list(
    space = "top",
    column = 4,
    points = list(
        pch = da$pch,
        fill = "white",
        col = da$color),
    lines = list(col = da$color),
    text = list(as.character(da$col), cex = 0.8)
)

print(xy1, split = c(1, 1, 2, 1), more = TRUE)
print(xy2, split = c(2, 1, 2, 1), more = FALSE)
draw.key(key = key, draw = TRUE,
         vp = grid::viewport(
             x = grid::unit(0.55, "npc"),
             y = grid::unit(0.92, "npc")))

```

O interesse nesse estudo é avaliar o relacionamento das variáveis
ambientais e genéticas. Para tal trabalhar-se-á com as matrizes de
distâncias para os dois conjuntos de variáveis. Para as variáveis
ambientais as distâncias serão calculadas conforme
\autoref{eqn:euclidean-dist}. Já para as variáveis genéticas, que tem a
restrição de soma 1, será utilizado a seguinte métrica de distância
\begin{equation}
    \label{eqn:proportion-dist}
    d(i, j) = \frac{1}{2}\sum_{k=1}^{6}\left | p_{ki}-p_{kj} \right |
\end{equation}

```{r distaxg, fig.height=6, fig.width=12, fig.cap="Matrizes de distâncias considerando as variáveis ambientais (esquerda) e genéticas (direita)."}

##----------------------------------------------------------------------
## Calcule and visualize distances matrices

ambD <- dist(da[, ambvars])
genD <- pdist(da[, genvars])

## Build data frame for use subscripts in lattice
## daD <- rbind(
##     cbind(melt(as.matrix(ambD)), vars = "Ambiental"),
##     cbind(melt(as.matrix(genD)), vars = "Genética")
## )
xy1 <- levelplot(value ~ Var1 + Var2 | vars,
          data = cbind(melt(as.matrix(ambD)),
                       vars = "Ambiental"),
          ## data = daD,
          colorkey = FALSE,
          xlab = "",
          ylab = "",
          scales = list(
              at = 1:16, labels = da$col,
              x= list(rot = 90)
          ),
          par.settings = list(
              layout.widths = list(right.padding = -2)
          ),
          panel = function(x, y, z, ...) {
                     ## print(as.list(...))
                     panel.levelplot(x, y, z, ...)
                     panel.text(x, y, round(z, 1), cex = 0.8)
                 })

xy2 <- levelplot(value ~ Var1 + Var2 | vars,
          data = cbind(melt(as.matrix(genD)),
                       vars = "Genética"),
          ## data = daD,
          colorkey = FALSE,
          xlab = "",
          ylab = "",
          scales = list(
              at = 1:16, labels = da$col,
              x= list(rot = 90)
          ),
          par.settings = list(
            layout.widths = list(left.padding = -2)
          ),
          panel = function(x, y, z, ...) {
                     ## print(as.list(...))
                     panel.levelplot(x, y, z, ...)
                     panel.text(x, y, round(z, 1), cex = 0.8)
                 })

print(xy1, split = c(1, 1, 2, 1), more = TRUE)
print(xy2, split = c(2, 1, 2, 1), more = FALSE)

```

As matrizes de distância entre as colônias considerando as variáveis
ambientais e genéticas são exibidas na \autoref{fig:distaxg}. Note que,
assim como já observado na \autoref{fig:splom-ecdf}, as colônias GH e GL
obtiveram as maiores distâncias. Agora considerando a matriz de
distâncias genéticas, temos as colônias LO e UO como as mais distantes.

Em posse das matrizes de distâncias entre as colônias para o conjunto de
variáveis ambientais e genéticas, procedeu-se com a realização do teste
de aleatorização matricial de Mantel a fim de avaliar se há correlação
positiva entre as distâncias ambientais e genéticas. O procedimento do
teste é basicamente i) aleatorizar os valores das matrizes e ii)
calcular o coeficiente de correlação entre as distâncias
aleatorizadas. Os passos i) e ii) são repetidos $N$ vezes para se obter
uma dsitribuição empírica das correlações sob a hipótese de correlação
nula e por fim a correlação calculada com base nas distâncias originais
é confrontada com essa distribuição.

```{r}

##----------------------------------------------------------------------
## Mantel test for correlation between ambiental and genetics distances
N <- 1000
out <- mantelTest(ambD, genD, nperm = N, graph = FALSE)

est <- round(out$correlation, 3)
pval <- round(out$p.value, 4)
dest <- round(out$nullcor, 3)
q95 <- round(quantile(dest, 0.95), 4)

```

A correlação entre as matrizes de distâncias ambientais e genéticas foi
de `r est`. Foram realizadas 1000 permutações das matrizes e calculadas
as correlações, cujo o qualtil de 95\% foi de `r q95`. Como $`r est` >
`r q95`$ há fortes evidências de que as distâncias ambientais
estejam positivamente correlacionadas com as distâncias genéticas.

Conforme análises apresentadas anteriormente mostra-se que há correlação
positiva à 5\% entre as variáveis ambientais e genéticas. Porém nessa
análsie foi negligenciada a posição espacial de cada colônia. Essa
informação pode estar associada aos resultados obtidos, uma vez que as
variáveis genéticas podem ser hereditárias e o processo migratório das
borboletas pode ter ocorrido entre colônias.

\pagebreak

# Análise de Componentes Principais

```{r}

##======================================================================
## Exercise chapter 6
##======================================================================

##----------------------------------------------------------------------
## Load and organize data
## help(ManlyTb6.6, h = "html")
da <- data.frame(scale(ManlyTb6.6))

##----------------------------------------------------------------------
## Compute principal components
out <- prcomp(da)
stddev <- out$sdev
loading <- out$rotation
scores <- out$x
propvar <- stddev^2 / sum(stddev^2)
pacum <- cumsum(propvar)
corr <- t(loading) * stddev

```

Esse exercício faz referência as técnicas apresentadas no capítulo 6 do
livro-texto. Os dados descrito no exercício é referente a um estudo
sobre taças de cerâmica escavadas de lugares pré-históricos na
Tailândia. Foram `r ncol(da)` medidas feitas em cada taça. Ao todo foram
mensuradas as medidas em `r nrow(da)` taças. A natureza das medidas pode
ser vista em @Manly2008[pág.102, Figura 6.3].

O objetivo nesse estudo é caracterizar as taças identificando grupos
com características similares e identificar, se houverem, taças
incomuns. O método apresentado nesse capítulo para atingir os objetivos
do estudo é via análise de componentes principais.

A construção dos componentes principais foi realizada via matriz de
correlação para que a amplitude de variação das variação não influencie
fortemente na análise. Os resultados da análise são apresentados na
\autoref{fig:biplot}.

O primeiro gráfico, superior à esquerda, da \autoref{fig:biplot} auxilia
a escolha que quantas componentes serão necessárias para explicar os
dados. Note que com duas componentes já explica-se `r round(pacum[2],
2)*100`\% da variância dos dados, o que já é bastante
satisfatório. Outro critério usualmente adotado é escolher tantas
componentes quanto fores os autovalores maiores que 1, nesse caso esse
critério também leva a escolha de apenas duas componentes (autovalores
`r round(stddev[1:2]^2, 3)`).

```{r biplot, fig.height=5, fig.width=10, fig.cap="Proporção acumulada da variância por cada componente com apresentação dos autovalores (superior à esquerda). Matriz de carregamentos, auto vetores, associados as 2 primeiras componentes (inferior à esquerda). Biplot (à direita), dispersão dos escores calculados com base nas 2 primeiras componentes e correlação das variáveis originais com as componentes."}

##----------------------------------------------------------------------
## Visualize analysis
varsname <- parse(text = paste("X[", seq(propvar), "]"))

## Alternative scree-plot (shows cumulative proportion of variance
## explained)

lambdas <- parse(text = paste0("lambda[", 1:6, "]~(",
                               round(stddev^2, 2), ")"))
xy1 <- xyplot(pacum ~ seq(propvar),
              pch = 19, type = c("l", "p"),
              xlab = "",
              ylab = "% variância explicada",
              xlim = c(0.5, 7),
              ylim = c(0.67, 1.03),
              scales = list(
                  x = list(at = seq(propvar),
                           labels = paste0("PC", seq(propvar)))
              ),
              panel = function(x, y, ...) {
                  panel.abline(h = seq(.7, 1, by = .05),
                               col = "lightgray", lty = 2)
                  panel.xyplot(x, y, ...)
                  panel.text(x + 0.45, y - 0.015, lambdas,
                             cex = 0.8)
              })

## Loadings of principal components
xy2 <- levelplot(loading[, 1:2],
                 xlab = "",
                 ylab = "",
                 scales = list(x = list(labels = varsname)),
                 aspect = "fill",
                 colorkey = FALSE,
                 ## colorkey = list(space = "bottom"),
                 at = seq(-1, 1, length.out = 20),
                 col.regions = colorRampPalette(
                     c(cols[3], "gray90", cols[2]))(100),
                 panel = function(x, y, z, ...) {
                     panel.levelplot(x, y, z, ...)
                     panel.text(x, y, round(z, 3), cex = 0.8)
                 })

##-------------------------------------------
## Biplot
limits <- c(-1, 1) * max(abs(scores[, 1:2])) * 1.1
xy3 <- xyplot(PC2 ~ PC1, data = as.data.frame(scores),
              scales = list(alternating = 1),
              xlab = "PC1",
              ylab = "PC2",
              xlim = limits,
              ylim = limits,
              par.settings = list(
                  layout.heights = list(top.padding = 4.5),
                  layout.widths = list(right.padding = 6.4)
              ),
              xscale.components = function(...) {
                  ans <- xscale.components.default(...)
                  ans$top <- ans$bottom
                  ans$top$ticks$tck <- 0
                  ans$bottom$ticks$tck <- 1
                  ans
              },
              yscale.components = function(...) {
                  ans <- yscale.components.default(...)
                  ans$right <- ans$left
                  ans$right$ticks$tck <- 0
                  ans$left$ticks$tck <- 1
                  ans
              },
              panel = function(x, y, ...) {
                  panel.abline(h = 0, v = 0, lty = 2,
                               col = "gray50")
                  panel.xyplot(x, y, alpha = 0.8,
                               pch = 19, cex = 1.1,
                               col = "gray50", ...)
                  panel.text(x + 0.1, y - 0.1, cex = 0.8,
                             rownames(da), ...)
              })
xy4 <- xyplot(-1:1 ~ -1:1,
              scales = list(
                  alternating = 2,
                  col = cols[2]
              ),
              xlab = "",
              ylab = "",
              xlab.top = list("Correlações com PC1", col = cols[2]),
              ylab.right = list("Correlações com PC2", col = cols[2]),
              par.settings = list(
                  layout.heights = list(bottom.padding = 4.5),
                  layout.widths = list(left.padding = 5.2)
              ),
              xscale.components = function(...) {
                  ans <- xscale.components.default(...)
                  ans$top <- ans$bottom
                  ans$top$ticks$tck <- 1
                  ans$bottom$ticks$tck <- 0
                  ans
              },
              yscale.components = function(...) {
                  ans <- yscale.components.default(...)
                  ans$right <- ans$left
                  ans$right$ticks$tck <- 1
                  ans$left$ticks$tck <- 0
                  ans
              },
              panel = function(x) {
                  panel.arrows(
                      x0 = 0, y0 = 0, col = cols[2],
                      x1 = corr[1, ], y1 = corr[2, ],
                      length = 0.1, angle = 20)
                  panel.text(x = corr[1, ] + 0.03,
                             y = corr[2, ] - 0.03,
                             varsname, col = cols[2])
              })


## Organize display
print(xy1, position = c(0.0, 0.4, 0.5, 1.0), more = TRUE)
print(xy2, position = c(0.0, 0.0, 0.5, 0.5), more = TRUE)
print(xy3, position = c(0.48, 0.0, 1.0, 1.0), more = TRUE)
print(xy4, position = c(0.48, 0.0, 1.0, 1.0), more = FALSE)

```

Já no segundo gráfico, inferior à esquerda da \autoref{fig:biplot},
têm-se os coeficientes da combinação linear das variáveis originais que
compõem as primeira e segunda componentes. Note que a primeira
componente é basicamente a soma de todas as variáveis originais, a
partir da definição das variáveis em @Manly2008[pág.102, Figura 6.3],
pode-se interpretar essa variável como o _tamanho_ da taça, uma vez que
valores altos definem uma taça grande e baixo uma taça menor. Para a
segunda componente temos basicamente um contraste de $X_1 + X_5$ contra
$X_3 + X_6$. $X_1$ e $X_5$ são medidas horizontais que definem a largura
da taça, enquanto que $X_3$ e $X_6$ são medidas verticais que definem
altura. Assim essa componente pode ser interpretada como _forma_, onde
taças mais "gordinhas" recebem valores altos e as mais "magrinhas"
valores baixos.

A última visualização apresentada na \autoref{fig:biplot} é o gráfico
_biplot_ [@Holland2008]. Nesse gráfico os escores de cada taça,
calculados a partir das componentes principais, são apresentados em um
gráfico de dispersão conjuntamente com a correlações entre as
componentes e as variáveis orginais, que são representadas pelos vetores
com valores em um eixo adicional. Observe que as taças 23, 24 e 22 se
destacam pelos valores baixos na primeira componente, isso as
caracteriza como taças baixas e com relação a segunda componente têm-se
um valor mediano para as três, ou seja, são taças pequenas e com formato
mediano. De forma geral nota-se que os escores da primeira componente
são bem mais variáveis que o da segunda, isso mostra que o tamanho das
taças é mais variado do que a forma. Para as correlações entre as
variáveis originais têm-se a mesma interpretação realizada a partir da
matriz de carregamentos. Valores altos da primeira componente estão
relacionados a valores altos de $X_1$, $X_2$, $X_3$, $X_4$, $X_5$ e
$X_6$ (correlações `r round(corr[1,], 2)`). A segunda componente
apresenta correlação negativa com $X_2$, $X_3$, $X_4$ e $X_6$ e
positivas com $X_1$ e $X_5$.


# Análise de Fatores

```{r, include=FALSE}

##======================================================================
## Exercise chapter 7
##======================================================================

##----------------------------------------------------------------------
## Packages
library(psych)
library(corrplot)

##----------------------------------------------------------------------
## Functions
outlierid <- function(dados, centerfun = median, n = 5, ...) {
    centro <- apply(dados, 2, centerfun, ...)
    dists  <- apply(dados, 1, function(x) sqrt(sum((x - centro)^2)))
    ident <- order(dists, decreasing = TRUE)[1:n]
    attr(ident, "dist") <- dists[ident]
    return(ident)
}

##----------------------------------------------------------------------
## Load and organize data
da <- ManlyTb6.7[, -c(1, 11)]
rownames(da) <- ManlyTb6.7[, 1]

## Correlation matrix
R <- cor(da)
colnames(R) <- rownames(R) <- paste0(":X[", seq(ncol(da)), "]")

```

Nesta seção será abordado o método de análise fatorial ou análise de
fatores, descrito no capítulo 7 do livro-texto. Os dados apresentados
para análise trazem estimativas do consumo médio de proteínas de
9 diferentes fontes de alimentos para os habitantes de 25 países
europeus. As variáveis foram codificadas da forma

* $X_1$: Consumo de proteínas provenientes de carne vermelha;
* $X_2$: Consumo de proteínas provenientes de carne branca;
* $X_3$: Consumo de proteínas provenientes de ovos;
* $X_4$: Consumo de proteínas provenientes de leite;
* $X_5$: Consumo de proteínas provenientes de peixe;
* $X_6$: Consumo de proteínas provenientes de cereais;
* $X_7$: Consumo de proteínas provenientes de carboidratos;
* $X_8$: Consumo de proteínas provenientes de grãos nozes e sementes
  oleaginosas; e
* $X_9$: Consumo de proteínas provenientes de frutas e vegetais.

Uma análise descritiva dos dados é fornecida na
\autoref{fig:corr-dens}. No gráfico à esquerda são apresentadas as
correlações entre as nove variáveis, essa é a matriz de correlações
amostrais a qual será denotada por $R$ nessa seção. Note que, em geral,
as variáveis apresentam fortes correlações com excessão de $X_9$ (frutas
e vegetais) cujo a correlação mais expressiva foi de apenas `r R[4, 9]`
ocorrida com $X_4$ (leite). Para as demais variáveis a correlação maior
correlação positiva foi entre $X_6$ e $X_8$ (`r R[6, 8]`) o que indica
altos consumos de proteínas de cereais é acompanhada de consumos altos
de grãos, nozes e sementes oleaginosas. E a maior corrrelação negativa
ocorre entre $X_3$ e $X_6$ indicando que valores de consumo altos de
proteínas provenientes de ovos estão realacionados a valores baixo de
consumo de proteínas provenientes de cerais e vice-e-versa.

A direita da \autoref{fig:corr-dens} são apresentadas as densidades
empíricas estimadas para cada variável. Note que todas as densidades
podem ser razoavelmente ajustadas por uma distribuição Normal, ou seja,
seus valores estão razoavelmente dispostos em acima e abaixo da
média. Para algumas variáveis nota-se uma bimodalidade mais acentuada,
por exemplo $X_2$ (carne branca) e $X_9$ (frutas e vegetais), e outras
apresentam certo grau de assimétria, por exemplo $X_5$ (peixe), $X_6$
(cereais) e $X_7$ (carboidratos).

```{r corr-dens, fig.height=5, fig.width=10, fig.cap="Representação da matriz de correlação dos dados (esquerda) e distribuições marginais empíricas das variáveis originais (direita)."}

##----------------------------------------------------------------------
## Descriptive data

## Build graphics
layout(mat = cbind(1, t(matrix(seq(2, l = 9), ncol = 3))),
       widths = c(11, 3, 3, 3)/20)
par(mai = c(0, 0, 0, 0))
col1 <- colorRampPalette(c("gray6", "gray40", "gray90",
                           "gray41", "gray5"))
corrplot.mixed(
    R,
    tl.col = "black",
    lower = "number", upper = "ellipse",
    number.cex = 1.1, tl.cex = 1.5, cl.cex = 1,
    upper.col = col1(20),
    lower.col = 1,
    mar = c(0, 0, 1, 0))
lapply(1:ncol(da), function(i) {
    par(mar = c(2, 1, 2, 1) + 0.1)
    d <- density(da[, i])
    plot(d$x, d$y, type = "n",
         xlab = "", ylab = "",
         main = "", axes = FALSE)
    axis(1)
    grid()
    box()
    polygon(x = c(d$x, rev(d$x)),
            y = c(d$y, rep(min(d$y), length(d$y))),
            col = "gray70", border = "white")
    mtext(parse(text = gsub(":", replace = "", colnames(R)[i])),
          line = -2)
})

```

A proposta deste exercício é a realização de uma análise fatorial a fim
de identificar fatores importantes que descrevam as variáveis observadas
além de avaliar o relacionamento entre os países.

```{r}

##----------------------------------------------------------------------
## Modelling - Get the factors and statistics

model <- principal(da, nfactors = 4, rotate = 'varimax')

lambdas <- model$values
loadings <- model$loadings
comunal <- model$communality
espvar <- model$uniquenesses
matres <- model$residual
propvar <- lambdas^2 / sum(lambdas^2)
scores <- model$scores

```

O modelo fatorial foi ajustado via método método das componentes
principais, cujo abordagem é via aproximação da matriz de correlações
$R$ por $LL^t + \Psi$, em que $L$ é a matriz de carregamentos fatoriais
e $\Psi$ a matriz diagonais das variâncias específicas
[@Johnson2007]. Dos nove fatores possíveis, permaneceu-se apenas com 3,
pois não há um considerável aumento no percentual de variação explicada
em cada variável com o acréscimo de um quarto fator. Ainda, para melhor
interpretação do relacionamento entre as variáveis e os fatores, os
fatores foram rotacionados. O modelo ajustado é apresentado na
\autoref{eqn:factors}.

```{r, results="asis"}

##-------------------------------------------
## Buid model expression
longnames <- c("Carne vermelha", "Carne branca", "Ovos", "Leite",
               "Peixes", "Cereais", "Carboidratos",
               "Grãos nozes e sementes", "Frutas e Vegetais")

cargas <- unclass(loadings)
expr_model <- do.call(
    rbind, lapply(1:nrow(cargas), function(i){
        ci <- formatC(cargas[i, ], 3, format = "f")
        cond <- !grepl("^-", ci)
        ci[cond] <- paste0("+", ci[cond])
        paste0(paste0("(\\text{", longnames[i], "})\\quad",
                      "&X_", i, "="),
               paste0(ci, "\\,F_", 1:ncol(cargas),
                      collapse = " "), "\\,+\\epsilon_", i, "\\\\")
    }))

cat("\\begin{equation}",
    "\\label{eqn:factors}",
    "\\begin{split}",
    expr_model,
    "\\end{split}",
    "\\end{equation}",
    sep= "\n")

```

As comunalidades para $X_1$, $X_2$, $X_3$, $X_4$, $X_5$, $X_6$, $X_7$,
$X_8$, $X_9$ são `r comunal` respectivamente. Note que as comunalidades
são todas altas indicando que muito da variação de $X_i$ pôde ser
explicada pelos 4 fatores comuns, para $i=1,2,\ldots, 9$. Uma avaliação
da qualidade do modelo pode ser realizado através dos gráficos à
esquerda da \autoref{fig:fact-plot}. Note que os resíduos variam de
-0.10 a 0.10 centrados e pouco dispersos em torno de 0 (boxplot
superior) o que indica um bom ajuste . Na matriz de resíduos (heatmap
inferior) pode-se verificar os resíduos para cada par de variáveis. Na
diagonal da matrix são apresentadas as variâncias específicas
(complementar das comunalidades) e da mesma forma indicam um bom ajuste.

Avaliando os coeficientes dos fatores no modelo expresso em
(\ref{eqn:factors}) nota-se que nas equações para $X_1$, $X_2$, $X_5$ e
$X_9$ há cargas bastante altas para somente um fator, sendo $F_1$ para
$X1$; $F_2$ para $X_2$; $F_3$ para $X_5$; e $F_4$ para $X_9$ isso indica
que a variação dessas variáveis é praticamente explicada por esse fator
de maior carga. Isso também evidencia a necessidade de 4 fatores, uma
vez que todos contribuem significativamente para explicação de alguma
variável. Nas equação que descrevem as demais variáveis há uma
composição de pelo menos 2 dos 4 fatores.

Ainda avaliando a \autoref{eqn:factors} é conveniente rótular os fatores,
avaliando as cargas estimados de um fator para todas as variáveis. Por
exemplo $F_1$ tem as maiores cargas para $X_1$ (carne vermelha), $X_3
(ovos)$, $X_4$ (leite) e $X_6$ (cereais), coeficientes
`r loadings[c(1, 2, 4, 6), 1]` respectivamente. Obviamente que "dar
nomes" aos fatores requer conhecimento prático dos dados analisados,
pesquisadores não envolvidos com a pesquisa tem dificuldade nessa
interpretação. Portanto, nesse trabalho não se rotulará os fatores.

```{r fact-plot, fig.height=5, fig.width=10, fig.cap="Avaliação da qualidade de ajuste do modelo. Distribuição dos resíduos calculados pela diferença entre $R$ e $LL^t + \\Psi$ (esquerda superior) e representação da matriz de resíduos (esquerda superior) e escores dos países com base nos quatro fatores obtidos (direita)."}

##-------------------------------------------
## Goodness of fit (residual matriz R - LL' + psi)
## cor(da) - ((loadings[]) %*% t(loadings[]) + diag(espvar))

varnames <- parse(text = paste("X[", 1:ncol(da), "]"))
diag(matres) <- 0
xy1 <- bwplot(c(matres),
              xlab = "",
              ylab = "",
              axis = axis.grid,
              par.settings = list(
                  layout.heights = list(
                      top.padding = 0,
                      bottom.padding = 0
                  ),
                  layout.widths = list(
                      right.padding = 0,
                      left.padding = 3
                  )
              ))

xy2 <- levelplot(matres,
                 xlab = "",
                 ylab = "",
                 aspect = "fill",
                 scales = list(labels = varnames),
                 at = seq(-max(abs(matres)), max(abs(matres)),
                          length.out = 12),
                 col.regions = colorRampPalette(
                     c(cols[3], "gray95", cols[2]))(50),
                 panel = function(x, y, z, ...) {
                     panel.levelplot(x, y, z, ...)
                     panel.text(1:9, 1:9,
                                formatC(espvar, 2, format = "f"))
                 })

##-------------------------------------------
## Visualize the scores
fanames <- parse(text = paste0("F[", 1:ncol(loadings), "]"))

## ## 3D visualization
## cloud(PC3 ~ PC1 * PC2,
##       data = data.frame(scores),
##       screen = list(z = 30, x = -80, y = 5),
##       xlab = "Fator 1",
##       ylab = "Fator 2",
##       zlab = "Fator 3",
##       scales = list(arrows = FALSE),
##       cex = 1.2,
##       axis = axis.grid,
##       panel = function(x, y, z, ...) {
##           panel.cloud(x = x, y = y, z = z,
##                       pch = 19, fill = 0, ...)
##       })
xy3 <- splom(~scores,
             varnames = fanames,
             xlab = "",
             groups = rownames(da),
             ## par.settings = list(
             ##     layout.heights = list(top.padding = 10)
             ## ),
             pscales = apply(scores, 2, function(x) {
                 list(limits = extendrange(x, f = 0.2))
             }),
             diag.panel = function(x, ...){
                 yrng <- current.panel.limits()$ylim
                 d <- density(x, na.rm = TRUE)
                 d$y <- with(d, yrng[1] + 0.9 * diff(yrng) * y / max(y))
                 panel.polygon(
                     x = c(d$x, rev(d$x)),
                     y = c(d$y, rep(min(d$y), length(d$y))),
                     col = "gray70", alpha = 0.9, border = "white")
                 diag.panel.splom(x, ...)
             },
             panel = function(x, y, groups, ...) {
                 panel.grid()
                 panel.abline(h = 0, v = 0, lty = 2, lwd = 0.8)
                 panel.points(x, y, col = "gray50", pch = 19,
                              cex = 1.1, alpha = 0.8)
                 labs <- rep("", length(x))
                 ind <- outlierid(cbind(x, y), n = 3)
                 labs[ind] <- groups[ind]
                 panel.text(x, y - 0.1, labs, cex = 0.65)
             })

## Organize visualization
print(xy1, position = c(0.0, 0.70, 0.5, 1.00), more = TRUE)
print(xy2, position = c(0.0, 0.00, 0.5, 0.80), more = TRUE)
print(xy3, position = c(0.5, 0.05, 1.0, 0.97), more = FALSE)

```

Na \autoref{tab:scores-fat} são apresentaos os escores calculados para
cada um dos 25 países europeus. Com os valores disposto nessa tabela
pode-se caracterizar a "habilidade", em termos de consumo de proteínas,
de cada país atráveis de seus escores obtidos. Uma visualização dos
escores dispostos na \autoref{tab:scores-fat} é realizada no gráfico à
direita na \autoref{fig:fact-plot}, em que os escores dos fatores são
apresentados dois a dois em gráficos de dispersão. Linhas que delimitam
os quadrantes são úteis para interpretação. Para todos os gráficos de
dispersão os 3 países mais distantes dos demais tem seus nomes
apresentados. Note que, quanto ao consumo de proteínas, não há nenhum
país foretemente discrepante da maioria, isso pode ser observado pelas
densidades empíricas apresentadas para os escores de cada fator.

```{r, results="asis"}

##-------------------------------------------
## Build table of scores
cap <- c("Escores dos fatores rotacionados para 23 países europeus.")
tab <- scores
colnames(tab) <- paste("Fator", 1:ncol(scores))
print(xtable(tab, digits = c(0, 4, 4, 4, 4),
             caption = cap,
             align = "lcccc",
             label = "tab:scores-fat")
      )

```


\pagebreak

# Análise de Função Discriminante

```{r}

##======================================================================
## Exercise chapter 8
##======================================================================

##----------------------------------------------------------------------
## Load packages
library(MASS)

##----------------------------------------------------------------------
## Load and organize data
## help(ManlyTb4.5, h = "html")
da <- transform(ManlyTb4.5, sexo = factor(sexo))
levels(da$grup) <- c("Modernos", "Pré-históricos",
                     "Chacais", "Cuons", "Indianos")
da$grup <- relevel(da$grup, ref = "Pré-históricos")
levels(da$sexo) <- c("Desconhecido", "Macho", "Fêmea")

##----------------------------------------------------------------------
## Get the discriminant functions

model <- lda(grup ~ ., data = da[, -11])
pred <- predict(model, da)

```

Essa seção é dedicada a realização do exercício proposto ao final do
capítulo 8 do livro-texto. O exercício propõe a realização de uma
análise discriminante a fim de separar grupos caninos com base em nove
medidas de mandíbula. Os dados são os mesmos utilizados na
\autoref{testes-de-significancia-com-dados-multivariados}. São
`r nrow(da)` observações, cujo 10 pertenciam ao grupo dos cães
Pré-históricos, 16 ao grupo dos cães Modernos, 20 ao grupo dos cães
Chacais, 17 ao grupo dos cães Cuons e 14 ao grupo cães Indianos. As nove
variáveis mensuradas são:

 * $X_1$ Comprimento da mandíbula (mm).
 * $X_2$ Largura da mandíbula, abaixo do primeiro molar (mm).
 * $X_3$ Largura do côndilo aricular (mm).
 * $X_4$ Altura da mandíbula, abaixo do primeiro molar (mm).
 * $X_5$ Comprimento do primeiro molar (mm).
 * $X_6$ Largura do primeiro molar (mm).
 * $X_7$ Comprimento do primeiro ao terceiro molar (mm).
 * $X_8$ Comprimento do primeiro ao quarto pré-molar (mm).
 * $X_9$ Largura do canino inferior (mm).

A \autoref{fig:plot-discrim} apresenta os resultados da análise
discriminante. Como são 5 grupos e o número de variáveis são nove têm-se
4 variáveis canônicas obtidas (LD1, LD2, LD3, LD4). A densidade de
probabilidade empírica estimada para cada variável canônica
estratificando por grupo canino é apresentada à esquerda da
\autoref{fig:plot-discrim}. Note que nesse gráfico é claro a atuação de
cada variável canônica na tarefa de discriminação. A LD1 discrimina
muito bem o grupo dos _Cuons_ dos demais; LD2 discrimina o grupo dos
_Indianos_; LD3 discrimina o grupo dos _Pré-históricos_ do grupo dos
_Chacais_; e LD4 tem pouco poder discriminativo. Complementar a
visualização das densidades empíricas, um gráfico de dispersão entre a
primeira e segunda variável canônica. Nota-se claramente a discriminação
dos grupos _Indianos_ e _Cuons_ na dimensão dessas duas variáveis. Nesse
também pode-se observar que as únicas classificações incorretas da
análise discriminante ocorreram para observações dos grupos
_Pré-históricos_ e _Modernos_, cujo nessa dimensão estão bastante
sobrepostos.

```{r plot-discrim, fig.height=5, fig.width=10, fig.cap="Densidades empíricas estimadas para as quatro variáveis canônicas estratificando pelos 5 grupos caninos (esquerda) e gráfico de dispersão das duas primeiras componentes (direita). No gráfico de dispersão o preenchimento dos pontos representa o grupo real e o contorno o grupo predito."}

##----------------------------------------------------------------------
## Visualization of quality prediction
pred <- predict(model, da)
aux <- cbind(data.frame(pred$x), grup = da$grup)
aux <- melt(aux, id.vars = "grup")

## Visualizing the discriminants scores
xy1 <- densityplot(~value | variable,
                   group = grup,
                   axis = axis.grid,
                   xlab = "",
                   ylab = "Densidade",
                   scales = list(x = "free"),
                   layout = c(2, 2),
                   as.table = TRUE,
                   data = aux)

xy2 <- xyplot(LD2 ~ LD1,
              ## groups = da$grup,
              groups = pred$class,
              type = c("g", "p"),
              data = data.frame(pred$x[, 1:2]),
              auto.key = list(lines = TRUE),
              par.settings = list(superpose.symbol = list(pch = 19)),
              cex = 1.2, pch = 19,
              panel = function(x, y, groups, ...) {
                  panel.xyplot(x, y, groups, ...)
                  panel.points(x, y, col = cols[da$grup],
                               pch = 19, cex = 0.5)
              })

print(xy1, split = c(1, 1, 2, 1), more = TRUE)
print(xy2, split = c(2, 1, 2, 1), more = FALSE)

```

Para possibilitar uma interpretação das variáveis canôninas, além da
discriminação dos grupos a \autoref{tab:scores-fat} apresenta as
correlações das variáveis originais com as variáveis
canônicas. Observa-se que a variável LD1 tem correlações positivas, mas
não fortes, com todas as variáveis originais exceto $X_7$ (comprimento
do primeiro ao terceiro molar) então pode-se intrepretá-la como tamanho
da arcada dentária em contraste com o comprimeiro do 1º ao 3º molar; LD2
tem todas as correlações fortes e negativas o que pode ser interpretado
como o inverso do tamanho da arcada dentária. Interpretações similares
podem ser realizadas com as demais variáveis canônicas e novamente um
conhecimento do estudo é imprescindível nessa etapa. Com as
interpretações das variáveis canôninas LD1 e LD2 pode-se voltar ao
gráfico de dispersão, à direita na \autoref{plot-discrim} e interpretar
a posição dos grupo. Por exemplo o grupo dos _Cuons_ apresentou valores
altos de LD1 o que indica que são cães com arcada dentária grande quando
contrastada com o comprimento do 1º ao 3º molar, já quando considerado a
tamanho da arcada dentária como um todo nota-se que o grupo tem arcada
dentária de um tamanho mediano (LD2 próximo de 0). Outro exemplo, no
grupo dos _Indianos_ é nítido que sua arcada dentária é maior que a dos
outros grupos, uma vez que os valores de LD2 neste grupo são negativos e
bem distantes de 0.

```{r, results="asis"}

## Correlations between canonical variables and original variables
codvars <- paste0("$X_", 1:ncol(model$means), "$")
corrs <- apply(pred$x, 2, function(x) {
    sapply(da[, -c(1, 11)], function(y) cor(x, y))
})
rownames(corrs) <- codvars

cap <- paste("Correlações entre as medidas de mandíbula originais",
             "e as quatro variáveis canônicas.")
print(xtable(t(corrs),
             digits = rep(3, 10),
             caption = cap,
             align = "lccccccccc",
             label = "tab:corrs",
             ),
      sanitize.colnames.function = identity)

```

Na \autoref{tab:errors} são apresentadas as classificações provenientes
da análise discriminante, que são realizadas pela probabilidade a
posteriori da observação pertencer a cada grupo calculada conforme
Teorema de Bayes. Nessa tabela têm-se a predição na própria base de
treino, o que potenciamente subestima o erro de classificação, e a
predição quando considerada a abordagem \textit{leave-one-out}, em que
ajusta-se o modelo de classificação sem retira a i-ésima observação e
posteriormente a classifica. Note que considerando ambas as matrizes
cruzadas o modelo de classificação baseado nas funções lineares
discriminantes de Fisher foram bastante satisfatórias.

\begin{table}[H]
\centering
\caption{Matrizes de confusão (grupos reais vs grupos
preditos). Preditos considerando a base de treino (esquerda) e
considerando a abordagem \textit{leave-one-out} (direita).}
\label{tab:errors}
%\begin{tabular}{r@{\hskip 0.3in}ccccc@{\hskip 0.3in}|@{\hskip 0.3in}ccccc}
\begin{tabular}{rccccc@{\hskip 0.3in}ccccc}
& \multicolumn{5}{c}{Predito base} & \multicolumn{5}{c}{Predito \textit{leave-one-out}} \\
\hline
Grupo real & \rotatebox{90}{Pré-históricos} & \rotatebox{90}{Modernos} &
 \rotatebox{90}{Chacais} & \rotatebox{90}{Cuons} &
 \rotatebox{90}{Indianos} & \rotatebox{90}{Pré-históricos} &
 \rotatebox{90}{Modernos} & \rotatebox{90}{Chacais} &
 \rotatebox{90}{Cuons} & \rotatebox{90}{Indianos} \\

```{r, results="asis"}

## Prediction error estimation via leave-one-out approach
pc_oov <- sapply(1:nrow(da), function(i) {
    model <- lda(grup ~ ., data = da[-i, -11])
    predict(model, da[i, ])$class
})

## Errors
errostab <- cbind(table(da$grup, pred$class),
                  table(da$grup, pc_oov))

print(xtable(errostab),
      only.contents = TRUE,
      include.colnames = FALSE)

```

\end{tabular}
\end{table}


## Regressão Logística

Essa subseção será bastante breve e compreende a segunda proposta de
exercício do capítulo 8 do livro-texto. Esse exercício propõe o ajuste
de uma regressão logística para discriminar o sexo dos cães em função
das medidas da mandíbula em cada grupo canino. Como são 9 medidas e
poucas observações em cada grupo canino abordagens para seleção de
variáveis deverão ser adotadas.

```{r}

##----------------------------------------------------------------------
## GLM Binomial model

## Fit models for each groups
subda <- droplevels(subset(da, sexo != "Desconhecido"))
subda <- split(subda[, -1], subda$grup)

models <- lapply(subda, function(data) {
    mnul <- glm(sexo ~ 1, data = data,
                family = "binomial")
    msat <- glm(sexo ~ ., data = data,
                family = "binomial")
    mfit <- step(mnul, direction = "both", trace = FALSE,
                 scope = list(lower = mnul, upper = msat))
    return(mfit)
})

```

O modelo denominado regressão logístico é um modelo da classe dos
modelos lineares generalizados, cujo a distribuição considerada para a
relação condicional $Y \mid X$ é Binomial($m$, $\pi$) e função de
ligação logito (que dá nome ao modelo). Assim o modelo pode ser escrito
da seguinte forma:

$$
\begin{aligned}
    Y_i \mid \underline{x}_i \sim \textrm{Binomial}(m_i, \, \pi_i) \\
    \log \left ( \frac{\pi_i}{ 1 - \pi_i} \right ) =
    \underline{x}_i^t\beta
\end{aligned}
$$

em que $Y_i$ é a variável aleatória dependente; $\underline{x}_i$ o vetor
de covariáveis do i-ésimo indivíduo; $m_i$ o número de ensaios de
Bernoulli realizados na i-ésima unidade amostral; $\pi_i$ a
probabilidade de sucesso; e $\beta$ os parâmetros do modelo a ser
ajustado.

No exemplo dessa seção a dimensão de $\underline{x}_i$ é
$9\times 1$, todavia como temos poucas observações em cada grupo canino
procedeu-se com o algoritmo _stepwise_ com critério AIC para seleção de
variáveis. Nesse algoritmo define-se o maior e menor modelo e o
algortimo irá, a partir do maior, retirar e recolar variáveis conforme
menor AIC. O algoritmo foi executado definindo o menor modelo como o
modelo sem covariáveis e o maior modelo aquele contendo as nove de forma
aditiva.

Os resultados dos modelos ajustados são exibidos na
\autoref{tab:glmbinom}, em que $\beta_j$ representa o efeito estimado da
variável $X_j$. Assim no grupo dos cães _Modernos_, permaneceram no
modelo apenas os efeitos das variáveis $X_7$ e $X_1$, para os _Chacais_
apenas os efeitos das variáveis $X_6$, $X_9$ e $X_1$ e assim por
diante. Note que as estimativas dos efeitos para os modelos dos grupos
_Chacais_ e _Indianos_ são demasiadamente altas, isso ocorreu devido a
probabilidades ajustadas como 1 e/ou 0, ou seja, nesse conjunto de
variáveis há um hiperplano que separa perfeitamente machos de
femêas. Isso é um problema estimação na borda do espaço paramétrico que
causa não convergência do algortimo de estimação. O único grupo em que
não se pôde discriminar machos e fêmeas através da regressão logística
foi o grupo dos cães _Cuons_, observe que nenhuma variável foi
selecionada para esse grupo, ou seja, a probabilidade de cães fêmeas
nesse grupo é `r predict(models[["Cuons"]], type = "response")[1]` para
qualquer cão independente de suas medidas da mandíbula.

```{r, results="asis"}

## Get estimates and analysis of deviance table
out <- do.call(
    rbind,
    lapply(models, function(model) {
        cbind("Estimativa" = coef(model),
              anova(model, test = "Chisq"))
    }))

columsname <- do.call(
    rbind,
    lapply(names(models), function(m) {
        co <- coef(models[[m]])
        grp_name <- c(m, rep(" ", length(co)-1))
        par_name <- sapply(names(co), function(x) {
            if (x == "(Intercept)") {
                return("$\\beta_0$")
            } else {
                ind <- which(x == colnames(subda[[1]]))
                paste0("$\\beta_", ind, "$")
            }
        })
        cbind(grp_name, par_name)
    }))


tabglm <- cbind(columsname, out)
colnames(tabglm)[1:2] <- c("Grupo", "Parameter")

cap <- paste("Estimativas dos parâmetros estimados dos modelos para",
             "cada grupo e seus respectivos quadros de análise de",
             "deviance sequencial.")
print(xtable(tabglm, caption = cap,
             digits = c(0, 0, 0, 3, 1, 3, 1, 3, 4),
             align = c("ccccccccc"),
             label = "tab:glmbinom"),
      include.rownames = FALSE,
      sanitize.text.function = identity)

```

\pagebreak

# Análise de Agrupamentos

```{r}

##======================================================================
## Exercise chapter 9
##======================================================================

##----------------------------------------------------------------------
## Packages
library(dendextend)
library(magrittr)

##----------------------------------------------------------------------
## Load and organize data
## help(ManlyTb9.7, h = "html")
da <- ManlyTb9.7
colnames(da)[-1] <- paste("Lote", 1:ncol(da[, -1]))
da_long <- melt(da, id.vars = "esp")

da_spec <- as.matrix(da[, -1])
rownames(da_spec) <- da$esp
da_lote <- t(as.matrix(da[, -1]))
rownames(da_lote) <- colnames(da)[-1]

```

Essa seção refere-se ao capítulo 9 do livro-texto. O exercício propõe a
realização de uma análise de agrupamentos. Os dados apresentados no
exercício mostram as quantidades das 25 espécies de plantas mais
abundantes em 17 lotes de um prado de pastagem em uma reserva natural na
Suécia. Ao todo são $25\times 17$ observações, ou seja, uma quantidade
mensurada para cada combinação de espécie e lote.

Um descrição dos dados é apresentada na \autoref{fig:boxplot9} onde
box-plots das medidas de abundância são construídos para cada espécie (à
esquerda) e para cada lote (à direita). Note que em geral as
distribuições das medidas são bastante assimétricas à direita, com
muitos valores baixos e poucos altos, as exceções ficam por conta das
espécies _Anemone nemorosa_, _Rumex acetosa_ e _Veronica Chamaedrys_ e
do _Lote 6_ que apresentam distribuições mais simétricas.

```{r boxplot9, fig.height=4.5, fig.width=11, fig.cap="Box-plots das medidas de abundância para as 25 espécies (esquerda) e para os 17 lotes (direita)."}

##----------------------------------------------------------------------
## Descriptive analysis
xy1 <- bwplot(value ~ esp, data = da_long,
              horizontal = FALSE,
              scales = list(x = list(rot = 45, cex = 0.8)),
              ylab = "",
              axis = axis.grid)
xy2 <- bwplot(value ~ variable, data = da_long,
              horizontal = FALSE,
              scales = list(x = list(rot = 45, cex = 0.8)),
              ylab = "",
              axis = axis.grid)

print(xy1, position = c(0.02, 0.0, 0.58, 1.0), more = TRUE)
print(xy2, position = c(0.55, 0.0, 1.0, 1.0), more = FALSE)

```

A análise de agrupamento desses dados será realizada sob duas
perspectivas. Na primeira agruparemos as espécies, avaliando as
similaridades das medidas de abundâncias dsitribuídas nos 17 diferentes
lotes. Sob a segunda perspectiva serão agrupados os lotes, a fim de
identificar grupos de lotes que tem abundância de espécies similares.

Nessa análise realizou-se um agrupamento hierárquico pelo método de
_Ward_ [@Murtagh2014] a partir das distâncias euclidianas entre os
vetores $\underline{x}_i$ ($i=1,2,\ldots,25$ vetores de tamanho 17 para
o agrupamento de espécies e $i=1,2,\ldots,17$ vetores de tamanho 25 para
o agrupamento de lotes).

```{r dendro, fig.height=4, fig.width=10, fig.cap="Dendrograma obtidos da análise de agrupamento hierárquico pelo método de Ward. Agrupamento de espécies (esquerda) e de lotes (direita)."}

##----------------------------------------------------------------------
## Clustering analysis

##-------------------------------------------
## By Species

## Grouping 10% most common words
k_spec <- 3 ## Decisão não automatizada, para agrupamento herárquico

mdist_spec <- dist(scale(da_spec))
agrup_spec <- hclust(mdist_spec, method = "ward.D")

## Build and show the dendogram
## par(mfrow = c(1, 2))
layout(matrix(c(1, 2), ncol = 2), widths = c(0.6, 0.4))
par(mar = c(8, 3, 1, 1) + 0.1)
dendr_spec <- as.dendrogram(agrup_spec)
dendr_spec %>%
    set("labels_cex", 0.9) %>%
    color_branches(k = k_spec) %>%
    plot(horiz = FALSE)
rect.dendrogram(dendr_spec, k = k_spec, horiz = FALSE,
                lty = 2, border = "gray30")

##-------------------------------------------
## By Lotes

## Grouping 10% most common words
k_lote = 2 ## Decisão não automatizada, para agrupamento herárquico

mdist_lote <- dist(scale(da_lote))
agrup_lote <- hclust(mdist_lote, method = "ward.D")

## Build and show the dendogram
par(mar = c(8, 1, 1, 1) + 0.1)
dendr_lote <- as.dendrogram(agrup_lote)
dendr_lote %>%
    set("labels_cex", 0.9) %>%
    color_branches(k = k_lote) %>%
    plot(horiz = FALSE)
rect.dendrogram(dendr_lote, k = k_lote, horiz = FALSE,
                lty = 2, border = "gray30")

```

Na \autoref{fig:dendro} são apresentados os resultados da análise de
agrupamentos para as espécies (à direita) e para os lotes (à
esquerda). Sem um apelo aplicado, neste trabalho optou-se pela adoção de
um algoritmo altomático para a definição do número de grupos. A
definição do número de grupos deu-se pelos grupos formados na maior
distância de ligação. Para espécies foram tomados três grupos e para os
lotes dois.

\pagebreak

# Análise de Correlação Canônica

```{r}

##======================================================================
## Exercise Chaper 10
##======================================================================

##----------------------------------------------------------------------
## Packages
library(corrplot)
library(CCA)

##----------------------------------------------------------------------
## Functions
outlierid <- function(dados, centerfun = median, n = 5, ...) {
    centro <- apply(dados, 2, centerfun, ...)
    dists  <- apply(dados, 1, function(x) sqrt(sum((x - centro)^2)))
    ident <- order(dists, decreasing = TRUE)[1:n]
    attr(ident, "dist") <- dists[ident]
    return(ident)
}

## Barlett Test for all canonical correlations equals 0
ccbarlett_test <- function(out) {
    ## `out` is output of CCA::cc() function
    with(out, {
        n <- nrow(scores$xscores)
        p <- nrow(scores$corr.X.xscores)
        q <- nrow(scores$corr.Y.xscores)
        l <- cor^2
        ## Statistic and test
        est <- -(n - (1/2) * (p + q + 3)) * sum(log(1 - l))
        pval <- pchisq(est, p * q, lower.tail = FALSE)
        list("est" = est, "pval" = pval)
    })
}

##----------------------------------------------------------------------
## Load and organize data
## help(ManlyTb10.4, h = "html")
## help(ManlyTb1.5, h = "html")
## help(ManlyTb6.7, h = "html")

da <- ManlyTb10.4

## Separe the datas
indX <- 2:10
indY <- 11:19
X <- da[, indX]
Y <- da[, indY]

```

Esta seção apresenta a análise dos dados apresentados no exercício
proposto ao final do 10º capítulo do livro-texto.  Os dados reference a
complementação daqueles analisados na \autoref{analise-de-fatores},
relembrando são dados com estimativas do consumo médio de proteínas de
9 diferentes fontes de alimentos para os habitantes de países
europeus. Para 22 desses países europeus também foram mensuradas as
porcentagens de força de trabalho empregadas em diferentes 9 diferentes
grupos de indústria.

Denotaremos o conjunto de variáveis de consumo de proteínas por $X_i$,
em que $i=1$ representa o consumo de proteínas provenientes de carne
vermelha; $i=2$ de carne branca; $i=3$ de ovos; $i=4$ de leite; $i=5$ de
peixe; $i=6$ de cereiais; $i=7$ de carboidratos; $i=8$ de grãos, nozes e
óleo de linhaça; e $i=9$ de frutas e verduras. E o conjunto de variáveis
sobre a força de trabalho será $Y_j$ sendo em $j=1$ a procentagem de
força de trabalho empregada em agricultara ; $j=2$ em mineração e
exploração de pedreiras; $j=3$ em fabricação; $j=4$ em fornecimento de
energia e água; $j=5$ em construção; $j=6$ em serviços; $j=7$ em
finanças; $j=8$ em serviço social e pessoal; e $j=9$ em transporte e
comunicações.

```{r corr18, fig.height=11, fig.width=11, fig.cap="Matriz de correlações amostrais entre todas as 18 variáveis mensuradas para 22 países europeus."}

##----------------------------------------------------------------------
## Descripte analysis
R <- cor(da[, c(indX, indY)])
colnames(R) <- rownames(R) <-
    c(paste0(":X[", seq(indX), "]"),
      paste0(":Y[", seq(indY), "]"))

col1 <- colorRampPalette(
    c("gray6", "gray40", "gray90", "gray41", "gray5"))
corrplot.mixed(
    R,
    tl.col = cols[2],
    lower = "number", upper = "ellipse",
    number.cex = 1, tl.cex = 1.5, cl.cex = 1,
    upper.col = col1(20),
    lower.col = 1,
    mar = c(0, 0, 1, 0))
par(xpd = TRUE)
rect(9.5, 9.5, 18.5, 18.5, border = cols[2], lwd = 2)
rect(0.5, 0.5, 9.5, 9.5, border = cols[2], lwd = 2)

```

As correlações dentre as variáveis $X_i$ e $Y_j$, $i,j=1,2,\ldots,9$ é
apresentada na \autoref{fig:corr18}. A diagnonal secundária da matriz de
correlações é destaca na figura para enfatizar que em análise de
correlação canônica estamos resumindo todas essas correlações. Em geral,
nota-se que há mais correlações fortes entre as variáveis de um mesmo
grupo do que entre variáveis de grupos diferentes, embora que nesse segundo
caso também se encontra correlações fortes, por exemplo $X_1$ (consumo de
carne vermelha) e $Y_7$ (força empregada no setor de finanças), com
correlação `r R[1, 16]` e $X_6$ (consumo de cereais) e $Y_8$ (serviço
social e pessoal), com `r R[6, 17]`.

```{r}

##----------------------------------------------------------------------
## Get the canonical variables and the canonical correlations
out <- cc(X, Y)
test <- ccbarlett_test(out)

## Correlations
corUX <- out$scores$corr.X.xscores
corVY <- out$scores$corr.Y.yscores

```

Como são nove variáveis em cada um dos grupos, foram obtidas 9
correlações canônicas `r out$cor` que são respectivas aos nove pares de
variáveis canônicas fornecidas pelo método. Note que são correlações
bastante fortes o que indica que há correlação entre o grupo de
variáveis $X_i$, sobre consumo de proteínas de diferentes fontes, e o
grupo $Y_j$, sobre as porcentagens de esforço de trabalho empregadas em
diferentes grupos de indústrias. O teste de Barlett aplicado as
correlações obtidas resultou em uma estatística F de `r test$est` que
comparada com a distribuição F de Snedecor com 64 graus de liberdade,
está bastante distante da região de alta probabilidade o que sugere
fortemente a rejeição da hipótese nula (_p-valor_ de $`r test$pval`$) de
que todas as correlações não são diferentes de 0. Isso evidência que
pelo menos uma das correlações canônicas é significante.

Uma das possibilidades interessantes da análise de correlação canônica é
a interpretação das variáveis canônicas geradas. Para auxiliar nessa
interpretação são apresentadas na \autoref{tab:corcc} as correlações das
variáveis canônicas com as variáveis originais. Como já enfatizado nas
seções anteriores para uma correta e completa interpretação se faz
necessário a avaliação de um pesquisador com conhecimentos sobre os
dados. Aqui far-se-á apenas uma breve interpretação para o primeiro par
de variáveis canônicas, $U_1$ e $V_1$. Note para $U_1$ que as
correlações são todas positivas com exceção de $X_6$ (consumo de
proteína de cereais) e $X_8$ (consumo de proteína de grão, nozes e óleo
de linhaça), então pode-se interpretar essa variável como um contraste
do consumo total de proteínas contra o consumo devido a proteínas
provenientes de cereias, grãos, nozes e linhaça. A variável canônica
$V_1$ é basicamente expressa pelo contraste de $Y_1$ (porcentagem
empregada a agricultura) e $Y_2$ (porcentagem empregada com mineração)
versus $Y_6$ (porcentagem empregada com serviços) e $Y_8$ (porcentagem
empregada com serviço social e pessoal). Como $U_1$ e $V_1$ são
positivamente correlacionadas pode-se dizer que os contraste definidos
anteriormente estão relacionados.

```{r, results="asis"}

## Coreelations between original variables
tabcor <- data.frame(paste0("$X_", 1:9, "$"), corUX[, 1:3],
                     paste0("$Y_", 1:9, "$"), corVY[, 1:3])
rownames(tabcor) <- NULL
colnames(tabcor) <- c("Variável", paste0("$U_", 1:3, "$"),
                      "Variável", paste0("$V_", 1:3, "$"))

cap <- paste("Correlações entre as variáveis canônicas e as",
             "variáveis originais")
print(xtable(tabcor, label = "tab:corcc",
             align = c("ccccccccc"),
             digits = 3,
             caption = cap),
      include.rownames = FALSE,
      sanitize.text.function = identity)

```

Na \autoref{fig:cancor} são apresentados gráficos que auxiliam a
avaliação e interpretação dos três primeiros e mais correlacionados
pares de variáveis canônicas. No primeiro gráfico à esquerda exibi-se a
dispersão dos valores das variáveis canônicas $U_1$ e $V_1$. Nesse
gráfico são destacados os países Albânia, Iugoslávia, Hungria e Romênia
com valores baixos de $U_1$ e $V_1$.

```{r cancor, fig.height=4, fig.width=12, fig.cap="Gráficos de dispersão entre os três primeiros pares de variáveis canônicas."}

##----------------------------------------------------------------------
## Visualize analysis
varnamesX <- parse(text = paste("X[", 1:ncol(X), "]"))
varnamesY <- parse(text = paste("Y[", 1:ncol(Y), "]"))

## Dispersion
xys <-
    lapply(1:3, function(i) {
        aux <- data.frame(U = out$scores$xscores[, i],
                          V = out$scores$yscores[, i])
        xlab <- parse(text = paste0(
                          "\"Variável canônica\"~U[", i, "]"))
        ylab <- parse(text = paste0(
                          "\"Variável canônica\"~V[", i, "]"))
        xyplot(V ~ U, data = aux,
               ## aspect = "iso",
               type = c("g", "p"),
               xlab = list(xlab, col = cols[2]),
               ylab = list(ylab, col = cols[3]),
               scales = list(
                   x = list(col = cols[2]),
                   y = list(col = cols[3])
               ),
               panel = function(x, y, ...) {
                   panel.xyplot(x, y, alpha = 0.8,
                                pch = 19, cex = 1.1,
                                col = "gray50", ...)
                   panel.abline(h = 0, v = 0, lty = 2,
                                col = "gray50")
                   ind <- outlierid(cbind(x, y), n = 4)
                   panel.text(x[ind], y[ind],
                              da$pais[ind],
                              cex = 0.75)
               })
    })

gridExtra::marrangeGrob(xys, ncol = 3, nrow = 1, top = "")

```

\pagebreak

# Escalonamento Multidimensional

```{r}

##======================================================================
## Exercise Chaper 11
##======================================================================

##----------------------------------------------------------------------
## Packages
library(MASS)

##----------------------------------------------------------------------
## Functions
outlierid <- function(dados, centerfun = median, n = 5, ...) {
    centro <- apply(dados, 2, centerfun, ...)
    dists  <- apply(dados, 1, function(x) sqrt(sum((x - centro)^2)))
    ident <- order(dists, decreasing = TRUE)[1:n]
    attr(ident, "dist") <- dists[ident]
    return(ident)
}

##----------------------------------------------------------------------
## Load and organize data
## help(ManlyTb1.5, h = "html")

da <- ManlyTb1.5
da$pais[21] <- "Rep. Tcheca"
rownames(da) <- paste0(da$pais, " (", da$grup, ")")

D <- dist(da[, -(1:2)])

```

Essa seção destina-se à aplicação da análise de escalonamento
multidimensional, descrita no capítulo 11 do livro-texto. Essa abordagem
é ideal para casos em que se mensura distâncias ou medidas de
dissimilaridade entre objetos. O objetivo da análise multidimensional é
reproduzir dimensões que reflitam a matriz de medidas de dissimilaridade
obtida.

A aplicação proposta nessa seção refere-se aos dados já apresentados
anteriormente na \autoref{analise-de-correlacao-canonica}, onde foram
apresentados os dados sobre empregos em países europeus. O estudo
mensurou a porcentagem da força de trabalho de empregados em nove
diferentes grupos de indústria (agricultura, floresta e pesca; mineração
e exploração de pedreiras; fabricação; fornecimento de energia e água;
construção; serviços; finanças; serviços sociais e pessoais; e
transportes e comunicações). Como aqui só considera-se os dados sobre
empregos, há dados sobre 30 países.

Vale ressaltar que em análises não didátivas têm-se apenas essa matriz
de dados observados, é incomum e não recomendável trabalhar somente com
as distâncias quando se tem os dados originais.

Na \autoref{fig:dist-mult} são apresentadas as distâncias calculadas
entre cada par de países. As siglas ao lado do nome de cada país indicam
o grupo político (UE, União Européia; AELC, área européia livre
comércio, países do leste europeu e outros países). No gráfico é nítido
a dissimilaridade da Albânia com relação a praticamente todos os países,
razoavelmente similar somente com a Turquia. Outra característica
marcante é a similaridade entre países de mesmo grupo político,
sobretudo destaca-se as semelhanças entre países da União Européia (UE)
e da área européia de livre comércio (AELC).

```{r dist-mult, fig.height=9.5, fig.width=9.5, fig.cap="Matriz de distância entre os países europeus considerando as porcentagens de trabalho empregada em cada setor industrial."}

##----------------------------------------------------------------------
## Descriptive analysis
levelplot(as.matrix(D),
          xlab = "",
          ylab = "",
          scales = list(x = list(rot = 40)),
          panel = function(x, y, z, ...) {
              ## print(as.list(...))
              panel.levelplot(x, y, z, ...)
              ## panel.text(x, y, round(z, 2), )
          })

```

A partir da matriz de distâncias procedeu-se com a análise de
escalonamento multidimensional. Considerou-se apenas o escalonamento
não-métrico de Kruskal. A definição do número de dimensões
necessárias para que se reflita adequadamente a matriz de distâncias foi
realizada por meio da avaliação do STRESS considerando diferentes
dimensões.

\begin{multicols}{2}

```{r stress-plot, fig.height=4, fig.width=5, out.width="0.5\\textwidth", fig.cap = "Valor de STRESS para diferentes números de dimensões no escalonamento multidimensional não-métrico de Kruskal."}

##----------------------------------------------------------------------
## Choose number of dimensions

kseq <- 1:10
mds <- lapply(kseq, function(k) {
    isoMDS(D, k = k, trace = FALSE)
})
meds <- sapply(mds, function(x) x$stress)

xyplot(meds ~ kseq,
       xlab = "Número de dimensões",
       ylab = "STRESS",
       type = c("g", "o"),
       pch = 19,
       scales = list(x = list(at = kseq)))

kchoose <- 4

```

\columnbreak

Na \autoref{fig:stress-plot} são exibidos os valores de STRESS
calculados para dimensões de 1 a 10. Note que claramente uma ou duas
dimensões são insatisfatórias, pois os valores de STRESS são superiores
a 5 e o decréscimo quando consideradas mais dimensões é expressivo. O
valor de STRESS para 3 dimensões foi de `r meds[3]` e para 4 dimensões
resultou em `r meds[4]` um decréscimo de `r -diff(meds[3:4])`. Para 5
dimensões o houve uma diminuição de apenas `r -diff(meds[4:5])`.
Portanto foram escolhidas 4 dimensões para representar a matriz de
distâncias apresentada na \autoref{fig:dist-mult}.

A representação das observações nas dimensões obtidas é apresenta na
\autoref{fig:dimen-plot} (à esquerda). Esse gráfica apresenta as
observações nas coordenadas de cada dimensões. Nota-se que algumas
dimensões podem ser intepretadas, por exemplo a dimensão 1 $D_1$, separa
bem os países do Leste europeu dos demais. Ao invertigar a tabela de
dados observa-se que países do leste investem mais força de trabalho em
agricultura, florestal e pesca e em mineração e exploração de pedreira e
tem porcentagens baixas para serviços.

\end{multicols}

\noindent O maior valor obtido nessa dimensão ocorreu para Albânia com
59.7 $u.m$.. A segunda dimensão tem dois países destacados na
extremidade inferior, esses são Hungria e Rep. Tcheca e da mesma forma
poderíamos elencar suas características para buscar interpretação dessa
dimensão.

```{r dimen-plot, fig.height=6, fig.width=11, fig.cap="Representação dos países europeus nas 4 dimensões obtidas pela análise multidimensional não métrica de Krukal (esquerda) e distâncias observadas e distâncias obtidas das dimensões conforme configuração da análise."}

##----------------------------------------------------------------------
## Visualize dimensions
dimen <- mds[[kchoose]]$points
dnames <- parse(text = paste("D[", 1:ncol(dimen), "]"))
xy1 <- splom(~dimen,
             varnames = dnames,
             xlab = "",
             groups = rownames(da),
             diag.panel = function(x, ...){
                 yrng <- current.panel.limits()$ylim
                 d <- density(x, na.rm = TRUE)
                 d$y <- with(d, yrng[1] + 0.9 * diff(yrng) * y / max(y))
                 panel.polygon(
                     x = c(d$x, rev(d$x)),
                     y = c(d$y, rep(min(d$y), length(d$y))),
                     col = "gray70", alpha = 0.4, border = "white")
                 diag.panel.splom(x, ...)
             },
             panel = function(x, y, groups, ...) {
                 panel.grid()
                 panel.abline(h = 0, v = 0, lty = 2, lwd = 0.8)
                 panel.points(x, y, col = "gray50", pch = 19,
                              cex = 1, alpha = 0.8)
                 ## labs <- rep("", length(x))
                 ## ind <- outlierid(cbind(x, y), n = 3)
                 ## labs[ind] <- groups[ind]
                 panel.text(x, y - 0.1, da$grup, cex = 0.65)
             })

## Recover the distances
aux <- data.frame("dreal" = c(D), "dconf" = c(dist(dimen)))
xy2 <- xyplot(dreal ~ dconf,
              xlab = "Distância de configuração",
              ylab = "Distância observada",
              type = c("g", "p", "r"),
              data = aux)

print(xy1, position = c(0, 0, 0.5, 1), more = TRUE)
print(xy2, position = c(0.5, 0, 1, 1), more = FALSE)

```

A direita da \autoref{fig:dimen-plot} têm-se uma avaliação da qualidade
do modelo 4-dimensional não-métrico. São apresentadas as distâncias
originais e as distâncias calculadas das quatro dimensões obtidas. O
esperado é que as dimensões recuperem as distâncias que foram utilizadas
na sua definição e como pode ser observado essa representação das
distâncias pelas 4 dimensões se mostra bastante satisfatória.

# Referências {-}

\setlength\parindent{0pt}


[carlos]: http://www.lce.esalq.usp.br/tadeu.html
